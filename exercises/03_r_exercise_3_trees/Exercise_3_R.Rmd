---
title: "R Exercise 3: INTA 6450 - Data Analytics and Security"
output: pdf_document
bibliography: references/references.bib
csl: references/ieee.csl
urlcolor: blue
# date: "2024-10-02"
---

```{r setup, include=FALSE, message=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache = TRUE)
```

# R Exercise 3

### Prompt

1. Complete the following exercise: 
  - RStudio exercise `trees.r`
2. You may make changes to the code to explore how they work
3. Then, submit the output for running these commands. 
You may copy/paste output from your terminal into a word or text document. 
You can convert the notebook to PDF submission:File->Compile Report->Report 
output format as HTML/PDF. 
4. Write 100-150 words describing one extension you made to the code. 
You may post the change description as a comment at the beginning of your code, 
or submit the write-up in a separate document. Make sure to clearly mark 
where in your code the changes were made either by commenting, highlighting, 
or noting the command lines where the changes occur. 

### Submissions

You will submit the following:

1. Original code output (R file code and output)
2. Your code change and output from that code change 
(comment where your code changes start and end)
3. Your code change description (this should be between 100 to 150 words)

An example of what the change description should look like:
```
#############################
# CHANGE DESCRIPTION
# 100-150 words on the changes I’ve made, including a reference to which 
# initial command I’ve changed >
# END OF CHANGE DESCRIPTION
#############################
```

Files must be in one of the following formats: pdf, doc, html

*Please note some of these exercises have graphs/charts - 
be sure when you export the original output to also check that the file 
includes graphs/charts that may have been present. 
If it does not, you will need to re-export or manually include the graphs in 
your final pdf, doc or html file*

\newpage
# Solution Summary

Receiver Operating Characteristic (ROC) curves are useful to evaluate performance
of binary classification models.
Code changes allowed for plotting ROC curves for different models to 
compare their performance visually.
An additional function is added to allow for creating a ROC curve plot using 
`ggplot2`. The function takes the true and predicted data as 
arguments and generates a ROC curve plot.
Area Under the Curve (AUC) is a single scalar value that summarizes the ROC curve. 
The AUC value is calculated and displayed on the plot. 
The plot is then saved to a file if a save path is provided.
This allows for comparing models by looking at their AUC scores or 
by observing which curve is closer to the top-left corner.
The code changes are attached below and followed up with the original
code output.

```{r, include=FALSE, eval = TRUE, message=FALSE, warning=FALSE, echo=FALSE}
# Instrumental Variables example
# install.packages("sem")
library(sem)
wages<-read.csv('http://inta.gatech.s3.amazonaws.com/wage2.csv')
iv.results<-tsls(lwage ~ educ + age + married + black, ~ feduc + age + married + black, data=wages)
# Run an instrumental variables regression. Note that father's education is
# used for an instrument, and is not in the first set of variables. Age,
# marital, status, and race are assumed to be less related to underlying
# ability and so are controlled for in the "first stage" regression too.

ols.results<-lm(lwage ~ educ + age + married + black, data=wages)
# Run the analogous OLS regression without father's education

print(summary(ols.results))
print(summary(iv.results))
# Note that the point estimate for education has now gone up. This suggests
# that people who have higher education in a way that's correlated with
# their father having higher education, even holding fixed age, marital
# status, and race, receive ~9% higher wages for every year of education
# Also note that the standard error on education is higher for the iv than
# ols results. The reason for this is that in IV, we're using only some of
# the variation in education: only the part related to father's education,
# so it's like there's less variation overall

# Stepwise regression and tree example
# install.packages(c('MASS','sem'))
library(MASS)
start.model<-lm(wage ~ hours + IQ + KWW + educ + exper + tenure + age + married + black + south + urban + sibs, data=wages)
# Give an initial model, which will be the most coefficients we'd want to ever use
summary(start.model)
stepwise.model<- step(start.model)
# The command "step" adds and subtracts coefficients to maximize a measure of
# goodness of fit, by default AIC
summary(stepwise.model)

# install.packages('tree')
library(tree)
wage.tree <- tree(wage ~ married + hours + IQ + KWW + educ + tenure + exper, method="anova", data=wages)
# fit a tree
summary(wage.tree)
# Print the results

plot(wage.tree)
text(wage.tree)
# Plot the tree, and add the text decisions

cross.validation <- cv.tree(wage.tree)
# perform cross-validation, 10-fold. 

cross.validation
# look for the size with the lowest "dev" or deviance
# Why might this be different than the fitted tree?

pruned.wage.tree<-prune.tree(wage.tree,best=5)
# Prune this tree down to 5 terminal nodes, just to show this is how you would
# do it. Here this makes it worse though
summary(pruned.wage.tree)

lmfit<- lm(wage ~ married + hours + IQ + KWW + educ + tenure + exper, data=wages)
# Compute a regression using those same variables:
anova(lmfit)
summary(wage.tree)
# Notice that the mean sum of squared residuals was 130895 using the linear
# model, compared to the residual mean deviance of 130000 using trees. So the
# tree method has less residual error, which means it's a better predictor.
# This is especially striking given that the tree only uses KWW, educ, IQ,
# While the regression needs substantial contributions from tenure, experience,
# and marital status too.

predict(wage.tree, newdata=data.frame(IQ=100, KWW=50, educ=16, married=1, hours=40, tenure=3, exper=2))
predict(lmfit, newdata=data.frame(IQ=100, KWW=50, educ=16, married=1, hours=40, tenure=3, exper=2))
# These predictors give different estimates for the expected wage of a
# particular individual, relatively young, married, well educated, with good
# knowledge of the world of work. Which would you trust and why?

# Extension: try to build another tree, and see what it looks like. 
# You can sample the data with the command:
# install.packages('dplyr')
# library('dplyr')
# wages.sample <- sample(wages, n=500) 

# Takehome exercise from last class
lfp <- read.csv('http://inta.gatech.s3.amazonaws.com/mroz_train.csv')
lfp$inlf<-as.factor(lfp$inlf) # We need the outcome variable to be a 'factor'

inlf.tree <-tree(as.numeric(inlf) - 1 ~huseduc + husage + kidslt6 + kidsge6 + nwifeinc + educ + age, data=lfp, na.action=na.omit) # Fit the model
inlf.lm <- lm(as.numeric(inlf) - 1 ~huseduc + husage + kidslt6 + kidsge6 + nwifeinc + educ + age, data=lfp) # Fit the model
print(inlf.tree)
# compute predictions manually, and save them as lfp$predicted.inlf
lfp$predicted.inlf<-predict(inlf.tree)


library(pROC)
evaluate <- function(y_true, y_predicted, detail=FALSE) {
  curve<-roc(y_true, y_predicted)
  if (detail) {
  print(ci.auc(curve))
  print('Sensitivity (True Positive Rate)')
  tpr<-ci.se(curve)
  print(tpr)
  print('Specificity (True Negative Rate)')
  tnr<-ci.sp(curve)
  print(tnr)
  }
  cat('Point estimate (final word on effectiveness)\n')
  print(auc(curve))
  #print('Point estimate of AUCROC: ' + auc(curve))
}
evaluate(lfp$inlf, lfp$predicted.inlf)


library(randomForest)
lfp <- read.csv('http://inta.gatech.s3.amazonaws.com/mroz_train.csv')
lfp[is.na(lfp)] <- 0
rf <-randomForest(as.factor(inlf) ~ hours  +  kidslt6  , data=lfp)
evaluate(as.factor(lfp$inlf), predict(rf,type="prob")[,1])

lfp.out <- read.csv('http://inta.gatech.s3.amazonaws.com/mroz_test.csv')
lfp.out[is.na(lfp.out)] <- 0
evaluate(as.factor(lfp.out$inlf), predict(rf, newdata=lfp.out, type="prob")[,1])
evaluate(lfp.out$inlf, predict(inlf.lm, newdata=lfp.out))
evaluate(lfp.out$inlf, predict(inlf.tree, newdata=lfp.out))
```

## Code Changes

```{r, eval = TRUE, message=FALSE, warning=FALSE}
library(ggplot2)

plot_roc_curve <- function(y_true, y_predicted, model_name, save_path=NULL) {
  # Compute the ROC curve
  curve <- roc(y_true, y_predicted)
  
  # Calculate the AUC value
  auc_value <- auc(curve)
  
  # Create the ROC plot using ggplot2
  plot <- ggroc(curve) + 
    ggtitle(paste("ROC Curve for", model_name)) +
    annotate("text", x = 0.6, y = 0.2, label = paste("AUC =", round(auc_value, 2)), size = 5)
  
  # Print the plot to the console
  print(plot)
  
  # Save the plot to a file if a save path is provided
  if (!is.null(save_path)) {
    ggsave(filename = save_path, plot = plot)
  }
}

# Plot ROC curves for the models and save them to files
plot_roc_curve(lfp.out$inlf, predict(rf, newdata=lfp.out, type="prob")[,1], 
  "Random Forest", 
  "random_forest_roc.png")
plot_roc_curve(lfp.out$inlf, predict(inlf.lm, newdata=lfp.out), 
  "Linear Model", 
  "linear_model_roc.png")
plot_roc_curve(lfp.out$inlf, predict(inlf.tree, newdata=lfp.out), 
  "Decision Tree", 
  "decision_tree_roc.png")
```

\newpage
## Original Code

```{r, eval = TRUE, message=FALSE, warning=FALSE}
# Instrumental Variables example
# install.packages("sem")
library(sem)
wages<-read.csv('http://inta.gatech.s3.amazonaws.com/wage2.csv')
iv.results<-tsls(lwage ~ educ + age + married + black, ~ feduc + age + married + black, data=wages)
# Run an instrumental variables regression. Note that father's education is
# used for an instrument, and is not in the first set of variables. Age,
# marital, status, and race are assumed to be less related to underlying
# ability and so are controlled for in the "first stage" regression too.

ols.results<-lm(lwage ~ educ + age + married + black, data=wages)
# Run the analogous OLS regression without father's education

print(summary(ols.results))
print(summary(iv.results))
# Note that the point estimate for education has now gone up. This suggests
# that people who have higher education in a way that's correlated with
# their father having higher education, even holding fixed age, marital
# status, and race, receive ~9% higher wages for every year of education
# Also note that the standard error on education is higher for the iv than
# ols results. The reason for this is that in IV, we're using only some of
# the variation in education: only the part related to father's education,
# so it's like there's less variation overall

# Stepwise regression and tree example
# install.packages(c('MASS','sem'))
library(MASS)
start.model<-lm(wage ~ hours + IQ + KWW + educ + exper + tenure + age + married + black + south + urban + sibs, data=wages)
# Give an initial model, which will be the most coefficients we'd want to ever use
summary(start.model)
stepwise.model<- step(start.model)
# The command "step" adds and subtracts coefficients to maximize a measure of
# goodness of fit, by default AIC
summary(stepwise.model)

# install.packages('tree')
library(tree)
wage.tree <- tree(wage ~ married + hours + IQ + KWW + educ + tenure + exper, method="anova", data=wages)
# fit a tree
summary(wage.tree)
# Print the results

plot(wage.tree)
text(wage.tree)
# Plot the tree, and add the text decisions

cross.validation <- cv.tree(wage.tree)
# perform cross-validation, 10-fold. 

cross.validation
# look for the size with the lowest "dev" or deviance
# Why might this be different than the fitted tree?

pruned.wage.tree<-prune.tree(wage.tree,best=5)
# Prune this tree down to 5 terminal nodes, just to show this is how you would
# do it. Here this makes it worse though
summary(pruned.wage.tree)

lmfit<- lm(wage ~ married + hours + IQ + KWW + educ + tenure + exper, data=wages)
# Compute a regression using those same variables:
anova(lmfit)
summary(wage.tree)
# Notice that the mean sum of squared residuals was 130895 using the linear
# model, compared to the residual mean deviance of 130000 using trees. So the
# tree method has less residual error, which means it's a better predictor.
# This is especially striking given that the tree only uses KWW, educ, IQ,
# While the regression needs substantial contributions from tenure, experience,
# and marital status too.

predict(wage.tree, newdata=data.frame(IQ=100, KWW=50, educ=16, married=1, hours=40, tenure=3, exper=2))
predict(lmfit, newdata=data.frame(IQ=100, KWW=50, educ=16, married=1, hours=40, tenure=3, exper=2))
# These predictors give different estimates for the expected wage of a
# particular individual, relatively young, married, well educated, with good
# knowledge of the world of work. Which would you trust and why?

# Extension: try to build another tree, and see what it looks like. 
# You can sample the data with the command:
# install.packages('dplyr')
# library('dplyr')
# wages.sample <- sample(wages, n=500) 

# Takehome exercise from last class
lfp <- read.csv('http://inta.gatech.s3.amazonaws.com/mroz_train.csv')
lfp$inlf<-as.factor(lfp$inlf) # We need the outcome variable to be a 'factor'

inlf.tree <-tree(as.numeric(inlf) - 1 ~huseduc + husage + kidslt6 + kidsge6 + nwifeinc + educ + age, data=lfp, na.action=na.omit) # Fit the model
inlf.lm <- lm(as.numeric(inlf) - 1 ~huseduc + husage + kidslt6 + kidsge6 + nwifeinc + educ + age, data=lfp) # Fit the model
print(inlf.tree)
# compute predictions manually, and save them as lfp$predicted.inlf
lfp$predicted.inlf<-predict(inlf.tree)


library(pROC)
evaluate <- function(y_true, y_predicted, detail=FALSE) {
  curve<-roc(y_true, y_predicted)
  if (detail) {
  print(ci.auc(curve))
  print('Sensitivity (True Positive Rate)')
  tpr<-ci.se(curve)
  print(tpr)
  print('Specificity (True Negative Rate)')
  tnr<-ci.sp(curve)
  print(tnr)
  }
  cat('Point estimate (final word on effectiveness)\n')
  print(auc(curve))
  #print('Point estimate of AUCROC: ' + auc(curve))
}
evaluate(lfp$inlf, lfp$predicted.inlf)


library(randomForest)
lfp <- read.csv('http://inta.gatech.s3.amazonaws.com/mroz_train.csv')
lfp[is.na(lfp)] <- 0
rf <-randomForest(as.factor(inlf) ~ hours  +  kidslt6  , data=lfp)
evaluate(as.factor(lfp$inlf), predict(rf,type="prob")[,1])

lfp.out <- read.csv('http://inta.gatech.s3.amazonaws.com/mroz_test.csv')
lfp.out[is.na(lfp.out)] <- 0
evaluate(as.factor(lfp.out$inlf), predict(rf, newdata=lfp.out, type="prob")[,1])
evaluate(lfp.out$inlf, predict(inlf.lm, newdata=lfp.out))
evaluate(lfp.out$inlf, predict(inlf.tree, newdata=lfp.out))
```